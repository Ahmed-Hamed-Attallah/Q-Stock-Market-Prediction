{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec5eb3f5",
   "metadata": {},
   "source": [
    "# Stock Market Prediction with LSTM\n",
    "\n",
    "**Generated notebook** for the uploaded CSV: `/mnt/data/portfolio_data.csv`.\n",
    "\n",
    "- Detected columns: `Date, AMZN, DPZ, BTC, NFLX`.\n",
    "- Suggested date column: `Date`.\n",
    "- Suggested target (price) column: `NFLX`.\n",
    "\n",
    "This notebook contains a full pipeline: EDA, preprocessing, LSTM model building, training, evaluation, and how to use the trained model for future predictions.\n",
    "\n",
    "Run the cells sequentially. If your CSV uses different column names, update the variables in the **Configuration** cell accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e986a1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - edit these if your column names differ\n",
    "CSV_PATH = r'/mnt/data/portfolio_data.csv'\n",
    "DATE_COL = 'Date'\n",
    "TARGET_COL = 'NFLX'\n",
    "TEST_SIZE = 0.2          # fraction of data to use for testing\n",
    "SEQUENCE_LENGTH = 60     # number of past days used to predict the next day\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50\n",
    "RANDOM_STATE = 42\n",
    "MODEL_SAVE_PATH = '/mnt/data/stock_lstm_model.h5'\n",
    "SCALER_SAVE_PATH = '/mnt/data/scaler.pkl'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549f963e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import pickle\n",
    "import os\n",
    "print('TensorFlow version:', tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ddef90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "print('Shape:', df.shape)\n",
    "print('Columns:', df.columns.tolist())\n",
    "display(df.head())\n",
    "\n",
    "# Ensure date column is datetime and sort by date if present\n",
    "if DATE_COL in df.columns:\n",
    "    df[DATE_COL] = pd.to_datetime(df[DATE_COL], errors='coerce')\n",
    "    df = df.sort_values(DATE_COL).reset_index(drop=True)\n",
    "    print(f'Using date column: {DATE_COL} (range: {df[DATE_COL].min()} to {df[DATE_COL].max()})')\n",
    "else:\n",
    "    print('Date column not found; proceeding without date index.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251043d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA - basic visualizations and checks\n",
    "# Plot target column\n",
    "if TARGET_COL in df.columns:\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(df[TARGET_COL], label=TARGET_COL)\n",
    "    plt.title(f'{TARGET_COL} over time')\n",
    "    plt.xlabel('Index (time-sorted rows)')\n",
    "    plt.ylabel(TARGET_COL)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(f'Target column {TARGET_COL} not found in data.')\n",
    "    \n",
    "# Check missing values and basic stats\n",
    "display(df.describe())\n",
    "print('\\nMissing values per column:')\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f87ad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "# We will use only the TARGET_COL for univariate LSTM (predict next price from past prices).\n",
    "data = df[[TARGET_COL]].copy()\n",
    "\n",
    "# Handle missing values by forward fill then backward fill\n",
    "data = data.fillna(method='ffill').fillna(method='bfill')\n",
    "\n",
    "# Scaling\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled = scaler.fit_transform(data.values.reshape(-1,1))\n",
    "\n",
    "# Save scaler for later use\n",
    "with open(SCALER_SAVE_PATH, 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "\n",
    "print('Scaled data shape:', scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af99559e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sequences for LSTM\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length, 0])\n",
    "        y.append(data[i+seq_length, 0])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "SEQ_LEN = SEQUENCE_LENGTH\n",
    "X, y = create_sequences(scaled, SEQ_LEN)\n",
    "print('X shape:', X.shape, 'y shape:', y.shape)\n",
    "\n",
    "# reshape X for LSTM [samples, time_steps, features]\n",
    "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "# Train/test split (time-series split, keep order)\n",
    "split_idx = int(X.shape[0] * (1 - TEST_SIZE))\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e0110c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LSTM model\n",
    "def build_lstm(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(64, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(LSTM(32, return_sequences=False))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "model = build_lstm((X_train.shape[1], X_train.shape[2]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbeeebf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6),\n",
    "    ModelCheckpoint(MODEL_SAVE_PATH, monitor='val_loss', save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_test, y_test),\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dcda52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation - plot training history and predictions\n",
    "plt.figure(figsize=(10,4))\n",
    "plt.plot(history.history['loss'], label='train_loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend(); plt.title('Loss'); plt.show()\n",
    "\n",
    "# Predictions (and inverse scale)\n",
    "preds = model.predict(X_test)\n",
    "# inverse transform\n",
    "with open(SCALER_SAVE_PATH, 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "preds_inv = scaler.inverse_transform(preds)\n",
    "y_test_inv = scaler.inverse_transform(y_test.reshape(-1,1))\n",
    "\n",
    "# Metrics\n",
    "mse = mean_squared_error(y_test_inv, preds_inv)\n",
    "mae = mean_absolute_error(y_test_inv, preds_inv)\n",
    "print(f'MSE: {mse:.4f}, MAE: {mae:.4f}')\n",
    "\n",
    "# Plot actual vs predicted\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.plot(y_test_inv, label='Actual')\n",
    "plt.plot(preds_inv, label='Predicted')\n",
    "plt.legend(); plt.title('Actual vs Predicted'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b27278c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model (already saved via ModelCheckpoint) and example single-step inference\n",
    "print('Model saved to', MODEL_SAVE_PATH)\n",
    "\n",
    "# Example: predict the next value after the last available sequence\n",
    "last_seq = scaled[-SEQ_LEN:].reshape(1, SEQ_LEN, 1)\n",
    "pred_scaled = model.predict(last_seq)\n",
    "pred_price = scaler.inverse_transform(pred_scaled)[0,0]\n",
    "print('Predicted next price (single-step):', pred_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895b18ef",
   "metadata": {},
   "source": [
    "## Notes & Next steps\n",
    "\n",
    "- This is a univariate LSTM using only the chosen target price column. For improved results, consider multivariate models using features like Open, High, Low, Volume, technical indicators (moving averages, RSI, MACD), and exogenous variables.\n",
    "- Try hyperparameter tuning (number of layers, units, learning rate, sequence length).\n",
    "- Consider using walk-forward validation for better time-series evaluation.\n",
    "- If your CSV uses different column names, change `DATE_COL` and `TARGET_COL` in the configuration cell.\n",
    "\n",
    "---\n",
    "\n",
    "*Notebook generated automatically.*"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
